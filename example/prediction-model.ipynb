{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Prediction model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# Include additional module\n",
    "include_path = '../tensorflow_oop/'\n",
    "if include_path not in sys.path:\n",
    "    sys.path.append(include_path)\n",
    "from tensorflow_oop.regression import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load dump of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: 36567 : [32, 3] -> [1, 3]\n"
     ]
    }
   ],
   "source": [
    "DUMP_PATH = '../data/moscow.dump'\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = TFDataset.load(DUMP_PATH)\n",
    "print('Dataset shape: %s' % (dataset.str_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset.set_batch_size(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting...\n",
      "Dataset shape: 36567 : [32, 3] -> [1, 3]\n",
      "Traininig  set shape: 25597 : [32, 3] -> [1, 3]\n",
      "Validation set shape: 5485 : [32, 3] -> [1, 3]\n",
      "Testing    set shape: 5485 : [32, 3] -> [1, 3]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RATE = 0.70\n",
    "VAL_RATE = 0.15\n",
    "TEST_RATE = 0.15\n",
    "SHUFFLE = False\n",
    "\n",
    "print('Splitting...')\n",
    "train_set, val_set, test_set = dataset.split(TRAIN_RATE, VAL_RATE, TEST_RATE, shuffle=SHUFFLE)\n",
    "print('Dataset shape: %s' % dataset.str_shape())\n",
    "print('Traininig  set shape: %s' % train_set.str_shape())\n",
    "print('Validation set shape: %s' % val_set.str_shape())\n",
    "print('Testing    set shape: %s' % test_set.str_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class TFWeatherForecast(TFRegressor):\n",
    "    def inference(self, inputs, **kwargs):\n",
    "        # Get parameters\n",
    "        input_size = self.inputs_shape[0]\n",
    "        hidden_size = kwargs['hidden_size']\n",
    "        rnn_count = kwargs['rnn_count']\n",
    "        output_size = self.outputs_shape[-1]\n",
    "\n",
    "        # Create RNN cells\n",
    "        def rnn_cell():\n",
    "            return tf.contrib.rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "        cells = [rnn_cell() for _ in range(rnn_count)]\n",
    "        multi_cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "        \n",
    "        # Stack RNN layers\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        init_state = multi_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        rnn_outputs, last_state = tf.nn.dynamic_rnn(cell=multi_cell,\n",
    "                                                    initial_state=init_state,\n",
    "                                                    inputs=inputs,\n",
    "                                                    swap_memory=True,\n",
    "                                                    time_major=False)\n",
    "\n",
    "        # Output layer\n",
    "        with tf.variable_scope('output'):\n",
    "            W = tf.Variable(tf.truncated_normal([hidden_size, output_size]),\n",
    "                            name='weight')\n",
    "            b = tf.Variable(tf.zeros([output_size]),\n",
    "                            name='bias')\n",
    "            outputs = tf.nn.xw_plus_b(last_state[-1].h, W, b)\n",
    "        return tf.reshape(outputs, [-1] + self.outputs_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start initializing model...\n",
      "Finish initializing model.\n",
      "TFNeuralNetwork object:\n",
      "                init: True\n",
      "              loaded: False\n",
      "             log_dir: /tmp/prediction-model\n",
      "        inputs_shape: [32, 3]\n",
      "       targets_shape: [1, 3]\n",
      "       outputs_shape: [1, 3]\n",
      "              inputs: Tensor(\"inputs:0\", shape=(?, 32, 3), dtype=float32)\n",
      "             targets: Tensor(\"targets:0\", shape=(?, 1, 3), dtype=float32)\n",
      "             outputs: Tensor(\"outputs:0\", shape=(?, 1, 3), dtype=float32)\n",
      "                loss: Tensor(\"loss:0\", shape=(), dtype=float32)\n",
      "         global_step: <tf.Variable 'global_step:0' shape=() dtype=int32_ref>\n",
      "                sess: <tensorflow.python.client.session.Session object at 0x7f2768442210>\n",
      "      summary_writer: <tensorflow.python.summary.writer.writer.FileWriter object at 0x7f276841afd0>\n",
      "    projector_config: \n",
      "              kwargs:\n",
      "                   hidden_size: 100\n",
      "                     rnn_count: 1\n",
      "             metrics:\n",
      "                   batch_train: ['loss']\n",
      "              batch_validation: ['loss']\n",
      "                     eval_test: []\n",
      "                    eval_train: []\n",
      "               eval_validation: []\n",
      "                     log_train: ['loss']\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = '/tmp/prediction-model'\n",
    "INPUTS_SHAPE = dataset.data_shape\n",
    "TARGETS_SHAPE = dataset.labels_shape\n",
    "OUTPUTS_SHAPE = dataset.labels_shape\n",
    "HIDDEN_SIZE = 100\n",
    "RNN_COUNT = 1\n",
    "\n",
    "model = TFWeatherForecast(log_dir=LOG_DIR)\n",
    "model.initialize(inputs_shape=INPUTS_SHAPE,\n",
    "                 targets_shape=TARGETS_SHAPE,\n",
    "                 outputs_shape=OUTPUTS_SHAPE,\n",
    "                 hidden_size=HIDDEN_SIZE,\n",
    "                 rnn_count=RNN_COUNT)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training iteration...\n",
      "         epoch_count: 1\n",
      "          iter_count: 800\n",
      "           optimizer: <class 'tensorflow.python.training.rmsprop.RMSPropOptimizer'>\n",
      "       learning_rate: 0.001\n",
      "  summarizing_period: 100\n",
      "      logging_period: 100\n",
      "   checkpoint_period: 10000\n",
      "   evaluation_period: 10000\n",
      "             metrics:\n",
      "                   batch_train: ['all_gradients', 'loss']\n",
      "              batch_validation: ['loss']\n",
      "                     eval_test: []\n",
      "                    eval_train: []\n",
      "               eval_validation: []\n",
      "                     log_train: ['loss']\n",
      "\n",
      "Iter 100 / 800 (epoch 0 / 1):   loss = 0.017192   [1.295 sec]\n",
      "Iter 200 / 800 (epoch 0 / 1):   loss = 0.008966   [1.399 sec]\n",
      "Iter 300 / 800 (epoch 0 / 1):   loss = 0.005135   [1.285 sec]\n",
      "Iter 400 / 800 (epoch 0 / 1):   loss = 0.006788   [1.298 sec]\n",
      "Iter 500 / 800 (epoch 0 / 1):   loss = 0.005100   [1.289 sec]\n",
      "Iter 600 / 800 (epoch 0 / 1):   loss = 0.001150   [1.334 sec]\n",
      "Iter 700 / 800 (epoch 0 / 1):   loss = 0.000896   [1.365 sec]\n",
      "Iter 800 / 800 (epoch 1 / 1):   loss = 0.001455   [1.314 sec]\n",
      "Saving checkpoint...\n",
      "INFO:tensorflow:/tmp/prediction-model/fit-checkpoint-800 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Model saved to: /tmp/prediction-model/fit-checkpoint-800\n",
      "Evaluation...\n",
      "Finish training iteration (total time 11.002 sec).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH_COUNT = 1\n",
    "\n",
    "model.fit(train_set, epoch_count=EPOCH_COUNT, val_set=val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Results on training   set: {}\n",
      "Results on validation set: {}\n",
      "Results on testing    set: {}\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating...')\n",
    "if train_set is not None:\n",
    "    train_eval = model.evaluate(train_set)\n",
    "    print('Results on training   set: %s' % train_eval)\n",
    "if val_set is not None:\n",
    "    val_eval = model.evaluate(val_set)\n",
    "    print('Results on validation set: %s' % val_eval)\n",
    "if test_set is not None:\n",
    "    test_eval = model.evaluate(test_set)\n",
    "    print('Results on testing    set: %s' % test_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
