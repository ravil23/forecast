{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# Include additional module\n",
    "include_path = '../tensorflow_oop/'\n",
    "if include_path not in sys.path:\n",
    "    sys.path.append(include_path)\n",
    "from tensorflow_oop.regression import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dump of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: 36567 [32, 3] -> [1, 3]\n"
     ]
    }
   ],
   "source": [
    "DUMP_PATH = '../data/moscow.dump'\n",
    "\n",
    "print('Loading dataset...')\n",
    "dataset = TFDataset.load(DUMP_PATH)\n",
    "print('Dataset shape: %s %s -> %s' % (dataset.size_, dataset.data_shape_, dataset.labels_shape_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset.set_batch_size(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting...\n",
      "Traininig  set shape: 25597 [32, 3] -> [1, 3]\n",
      "Validation set shape: 5485 [32, 3] -> [1, 3]\n",
      "Testing    set shape: 5485 [32, 3] -> [1, 3]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RATE = 0.70\n",
    "VAL_RATE = 0.15\n",
    "TEST_RATE = 0.15\n",
    "SHUFFLE = False\n",
    "\n",
    "print('Splitting...')\n",
    "train_set, val_set, test_set = dataset.split(TRAIN_RATE, VAL_RATE, TEST_RATE, shuffle=SHUFFLE)\n",
    "print('Traininig  set shape: %s %s -> %s' % (train_set.size_, train_set.data_shape_, train_set.labels_shape_))\n",
    "print('Validation set shape: %s %s -> %s' % (val_set.size_,   val_set.data_shape_,   val_set.labels_shape_))\n",
    "print('Testing    set shape: %s %s -> %s' % (test_set.size_,  test_set.data_shape_,  test_set.labels_shape_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TFWeatherForecast(TFRegressor):\n",
    "    def inference(self, inputs, **kwargs):\n",
    "        input_size = self.inputs_shape_[0]\n",
    "        hidden_size = kwargs['hidden_size']\n",
    "        rnn_count = kwargs['rnn_count']\n",
    "        output_size = self.outputs_shape_[-1]\n",
    "        def rnn_cell():\n",
    "            return tf.contrib.rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "        cells = [rnn_cell() for _ in range(rnn_count)]\n",
    "        multi_cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        init_state = multi_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        rnn_outputs, last_state = tf.nn.dynamic_rnn(cell=multi_cell,\n",
    "                                                    initial_state=init_state,\n",
    "                                                    inputs=inputs,\n",
    "                                                    time_major=False)\n",
    "        W = tf.Variable(tf.truncated_normal([hidden_size, output_size]))\n",
    "        b = tf.Variable(tf.zeros([output_size]))\n",
    "        outputs = tf.nn.xw_plus_b(last_state[-1].h, W, b)\n",
    "        return tf.reshape(outputs, [-1] + self.outputs_shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start initializing model...\n",
      "Finish initializing model.\n",
      "TFNeuralNetwork object:\n",
      "            log_dir_: /tmp/prediction-model\n",
      "       inputs_shape_: [32, 3]\n",
      "      outputs_shape_: [1, 3]\n",
      "   data_placeholder_: Tensor(\"input_data:0\", shape=(?, 32, 3), dtype=float32)\n",
      " labels_placeholder_: Tensor(\"input_labels:0\", shape=(?, 1, 3), dtype=float32)\n",
      "            outputs_: Tensor(\"output_layer:0\", shape=(?, 1, 3), dtype=float32)\n",
      "            metrics_: {'loss': <tf.Tensor 'loss:0' shape=() dtype=float32>}\n",
      "               loss_: Tensor(\"loss:0\", shape=(), dtype=float32)\n",
      "               sess_: <tensorflow.python.client.session.Session object at 0x11733ae10>\n",
      "             kwargs_: {'hidden_size': 100, 'rnn_count': 1}\n",
      "            summary_: Tensor(\"Merge/MergeSummary:0\", shape=(), dtype=string)\n",
      "     summary_writer_: <tensorflow.python.summary.writer.writer.FileWriter object at 0x1173a0dd8>\n",
      "   projector_config_: \n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = '/tmp/prediction-model'\n",
    "INPUTS_SHAPE = dataset.data_shape_\n",
    "OUTPUTS_SHAPE = dataset.labels_shape_\n",
    "HIDDEN_SIZE = 100\n",
    "RNN_COUNT = 1\n",
    "\n",
    "model = TFWeatherForecast(log_dir=LOG_DIR,\n",
    "                          inputs_shape=INPUTS_SHAPE,\n",
    "                          outputs_shape=OUTPUTS_SHAPE,\n",
    "                          hidden_size=HIDDEN_SIZE,\n",
    "                          rnn_count=RNN_COUNT)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training iteration...\n",
      "Iteration 100 / 800 (epoch 0 / 1):   loss = 0.006551   [5.535 sec]\n",
      "Iteration 200 / 800 (epoch 0 / 1):   loss = 0.023786   [5.445 sec]\n",
      "Iteration 300 / 800 (epoch 0 / 1):   loss = 0.004921   [5.219 sec]\n",
      "Iteration 400 / 800 (epoch 0 / 1):   loss = 0.012909   [5.158 sec]\n",
      "Iteration 500 / 800 (epoch 0 / 1):   loss = 0.005228   [5.429 sec]\n",
      "Iteration 600 / 800 (epoch 0 / 1):   loss = 0.004367   [5.160 sec]\n",
      "Iteration 700 / 800 (epoch 0 / 1):   loss = 0.003515   [5.265 sec]\n",
      "Iteration 800 / 800 (epoch 1 / 1):   loss = 0.001730   [5.387 sec]\n",
      "Saving checkpoint...\n",
      "INFO:tensorflow:/tmp/prediction-model/fit-checkpoint-800 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Model saved to: /tmp/prediction-model/fit-checkpoint-800\n",
      "Evaluation...\n",
      "Evaluation on full dataset:   [training   set]   loss = 0.001891   [4.762 sec]\n",
      "Evaluation on full dataset:   [validation set]   loss = 0.001956   [1.062 sec]\n",
      "Finish training iteration (total time 60.431 sec).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCH_COUNT = 1\n",
    "\n",
    "model.fit(train_set, iteration_count=None, epoch_count=EPOCH_COUNT, val_set=val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Results on training   set: {'loss': 0.0018911378}\n",
      "Results on validation set: {'loss': 0.0019556019}\n",
      "Results on testing    set: {'loss': 0.0016928277}\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating...')\n",
    "if train_set is not None:\n",
    "    train_eval = model.evaluate(train_set)\n",
    "    print('Results on training   set: %s' % train_eval)\n",
    "if val_set is not None:\n",
    "    val_eval = model.evaluate(val_set)\n",
    "    print('Results on validation set: %s' % val_eval)\n",
    "if test_set is not None:\n",
    "    test_eval = model.evaluate(test_set)\n",
    "    print('Results on testing    set: %s' % test_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
