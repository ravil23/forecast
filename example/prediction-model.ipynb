{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# Include additional module\n",
    "include_path = '../include'\n",
    "if include_path not in sys.path:\n",
    "    sys.path.append(include_path)\n",
    "from tensorflow_oop import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dump of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: 36566 [32, 3] -> [1, 3]\n"
     ]
    }
   ],
   "source": [
    "DUMP_PATH = '../data/moscow.dump'\n",
    "\n",
    "print 'Loading dataset...'\n",
    "dataset = TFDataset()\n",
    "dataset.load(DUMP_PATH)\n",
    "print 'Dataset shape:', dataset.size_, dataset.data_shape_, '->', dataset.labels_shape_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset.set_batch_size(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting...\n",
      "Traininig  set shape: 25596 [32, 3] -> [1, 3]\n",
      "Validation set shape: 5486 [32, 3] -> [1, 3]\n",
      "Testing    set shape: 5484 [32, 3] -> [1, 3]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RATE = 0.70\n",
    "VAL_RATE = 0.15\n",
    "TEST_RATE = 0.15\n",
    "\n",
    "print 'Splitting...'\n",
    "train_set, val_set, test_set = dataset.split(TRAIN_RATE, VAL_RATE, TEST_RATE, shuffle=False)\n",
    "print 'Traininig  set shape:', train_set.size_, train_set.data_shape_, '->', train_set.labels_shape_\n",
    "print 'Validation set shape:', val_set.size_, val_set.data_shape_, '->', val_set.labels_shape_\n",
    "print 'Testing    set shape:', test_set.size_, test_set.data_shape_, '->', test_set.labels_shape_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set.shuffle()\n",
    "val_set.shuffle()\n",
    "test_set.shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFWeatherForecast(TFRegressor):\n",
    "    def inference(self, inputs, kwargs={}):\n",
    "        hidden_size = 100\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple=True)\n",
    "        rnn_outputs, final_state = tf.nn.dynamic_rnn(cell,\n",
    "                                                     inputs,\n",
    "                                                     dtype=tf.float32,\n",
    "                                                     time_major=False)\n",
    "        W = tf.Variable(tf.truncated_normal([hidden_size, self.outputs_shape_[-1]]))\n",
    "        b = tf.Variable(tf.zeros([self.outputs_shape_[-1]]))\n",
    "        outputs = tf.nn.xw_plus_b(rnn_outputs[:,-1], W, b)\n",
    "        return tf.reshape(outputs, [-1] + self.outputs_shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start initializing model...\n",
      "Finish initializing model.\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = '/tmp/prediction-model'\n",
    "INPUTS_SHAPE = dataset.data_shape_\n",
    "OUTPUTS_SHAPE = dataset.labels_shape_\n",
    "\n",
    "model = TFWeatherForecast(log_dir=LOG_DIR, inputs_shape=INPUTS_SHAPE, outputs_shape=OUTPUTS_SHAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training iteration...\n",
      "Epoch 1/23:   loss = 0.109162   (61.495 sec)\n",
      "Epoch 2/23:   loss = 0.105373   (61.653 sec)\n",
      "Epoch 3/23:   loss = 0.098353   (61.931 sec)\n",
      "Epoch 4/23:   loss = 0.093958   (62.268 sec)\n",
      "Epoch 5/23:   loss = 0.088209   (61.602 sec)\n",
      "Epoch 6/23:   loss = 0.087645   (62.137 sec)\n",
      "Epoch 7/23:   loss = 0.086160   (61.596 sec)\n",
      "Epoch 8/23:   loss = 0.086382   (61.667 sec)\n",
      "Epoch 9/23:   loss = 0.086553   (61.468 sec)\n",
      "Epoch 10/23:   loss = 0.085446   (61.982 sec)\n",
      "Epoch 11/23:   loss = 0.088529   (64.612 sec)\n",
      "Epoch 12/23:   loss = 0.085449   (61.904 sec)\n",
      "Epoch 13/23:   loss = 0.085235   (61.778 sec)\n",
      "Epoch 14/23:   loss = 0.087202   (62.191 sec)\n",
      "Epoch 15/23:   loss = 0.087553   (61.337 sec)\n",
      "Epoch 16/23:   loss = 0.087610   (61.453 sec)\n",
      "Epoch 17/23:   loss = 0.088355   (62.157 sec)\n",
      "Epoch 18/23:   loss = 0.092566   (61.314 sec)\n",
      "Epoch 19/23:   loss = 0.090375   (62.123 sec)\n",
      "Epoch 20/23:   loss = 0.091075   (61.442 sec)\n",
      "Epoch 21/23:   loss = 0.092651   (61.683 sec)\n",
      "Epoch 22/23:   loss = 0.090999   (61.836 sec)\n",
      "Epoch 23/23:   loss = 0.091148   (61.681 sec)\n",
      "Model saved to: /tmp/prediction-model/fit-checkpoint\n",
      "Finish training iteration.\n"
     ]
    }
   ],
   "source": [
    "EPOCH_COUNT = 23\n",
    "\n",
    "model.fit(train_set, EPOCH_COUNT, val_set=val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.053702202}\n",
      "{'loss': 0.091147743}\n",
      "{'loss': 0.074106276}\n"
     ]
    }
   ],
   "source": [
    "print model.evaluate(train_set)\n",
    "print model.evaluate(val_set)\n",
    "print model.evaluate(test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
